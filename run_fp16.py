import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['OMP_NUM_THREADS'] = '1'
import sys
import torch
import torchvision
import numpy as np
import cv2
import requests
from tqdm import tqdm
from types import ModuleType
import openvino as ov
from openvino.runtime import Core, properties
import time
import openvino.runtime.properties as props
from openvino.runtime import Type  # æ·»åŠ ç±»å‹æ”¯æŒ
# ========== å…¼å®¹æ€§ä¿®å¤å±‚ ==========
# ç¡®ä¿ functional_tensor æ¨¡å—å­˜åœ¨
if not hasattr(torchvision.transforms, 'functional_tensor'):
    functional_tensor = ModuleType('torchvision.transforms.functional_tensor')
    sys.modules['torchvision.transforms.functional_tensor'] = functional_tensor
    torchvision.transforms.functional_tensor = functional_tensor
    print("âœ… å·²åˆ›å»º functional_tensor å…¼å®¹æ¨¡å—")


from torchvision.transforms import functional as F

# æ·»åŠ éœ€è¦çš„å‡½æ•°åˆ° functional_tensor
for func_name in ['rgb_to_grayscale', 'adjust_brightness', 'adjust_contrast', 'adjust_saturation']:
    if hasattr(F, func_name) and not hasattr(torchvision.transforms.functional_tensor, func_name):
        setattr(torchvision.transforms.functional_tensor, func_name, getattr(F, func_name))
        print(f"âœ… å·²æ·»åŠ  {func_name} åˆ° functional_tensor")
# ================================

# ========== æ¨¡å‹è·¯å¾„ ==========
MODEL_DIR = "../FP16/models"
os.makedirs(MODEL_DIR, exist_ok=True)
MODEL_NAME = "RealESRGAN_x4plus.pth"
MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)


# ================================

# ========== ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ ==========
def download_model():
    """ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶"""
    if os.path.exists(MODEL_PATH):
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨: {MODEL_PATH}")
        return True

    # ä¸‹è½½é“¾æ¥
    model_url = "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth"

    print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶: {MODEL_NAME}...")

    try:
        response = requests.get(model_url, stream=True)
        response.raise_for_status()

        total_size = int(response.headers.get('content-length', 0))
        block_size = 1024  # 1KB

        with open(MODEL_PATH, 'wb') as f, tqdm(
                desc=MODEL_NAME,
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024,
        ) as bar:
            for data in response.iter_content(block_size):
                bar.update(len(data))
                f.write(data)

        print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {MODEL_PATH}")
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False


# ========== å¯¼å‡º ONNX æ¨¡å‹ ==========
def export_realesrgan_to_onnx():
    """å¯¼å‡º RealESRGAN æ¨¡å‹ä¸º ONNX æ ¼å¼"""
    print("åˆå§‹åŒ– RealESRGAN æ¨¡å‹...")

    try:
        # æ˜¾å¼å¯¼å…¥æ¨¡å‹æ¶æ„
        from basicsr.archs.rrdbnet_arch import RRDBNet

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = RRDBNet(
            num_in_ch=3,
            num_out_ch=3,
            num_feat=64,
            num_block=23,
            num_grow_ch=32,
            scale=4
        )
        print("âœ… æ¨¡å‹æ¶æ„åˆ›å»ºæˆåŠŸ")

        # åŠ è½½æ¨¡å‹æƒé‡
        state_dict = torch.load(MODEL_PATH, map_location='cpu')
        print(f"âœ… æƒé‡æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå¤§å°: {len(state_dict)} keys")

        # è¯†åˆ«å¹¶åŠ è½½æƒé‡æ ¼å¼
        if 'params_ema' in state_dict:
            print("ğŸ” æ£€æµ‹åˆ° 'params_ema' æƒé‡æ ¼å¼")
            model.load_state_dict(state_dict['params_ema'])
        elif 'params' in state_dict:
            print("ğŸ” æ£€æµ‹åˆ° 'params' æƒé‡æ ¼å¼")
            model.load_state_dict(state_dict['params'])
        elif 'model' in state_dict:
            print("ğŸ” æ£€æµ‹åˆ° 'model' æƒé‡æ ¼å¼")
            model.load_state_dict(state_dict['model'])
        else:
            print("ğŸ” æ£€æµ‹åˆ°ç›´æ¥æ¨¡å‹æƒé‡æ ¼å¼")
            model.load_state_dict(state_dict)

        model.eval()
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ")

        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
        dummy_input = torch.randn(1, 3, 64, 64)

        # å¯¼å‡ºä¸º ONNX
        onnx_path = "../FP16/realesrgan_x4.onnx"
        print(f"å¯¼å‡ºæ¨¡å‹åˆ° {onnx_path}...")

        torch.onnx.export(
            model,
            dummy_input,
            onnx_path,
            opset_version=14,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {2: 'height', 3: 'width'},
                'output': {2: 'height', 3: 'width'}
            }
        )

        # éªŒè¯ ONNX æ–‡ä»¶ç”Ÿæˆ
        if os.path.exists(onnx_path):
            print(f"âœ… ONNX å¯¼å‡ºå®Œæˆ: {onnx_path}")
            return onnx_path
        else:
            print(f"âŒ ONNX æ–‡ä»¶æœªç”Ÿæˆ")
            return None

    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

# è½¬æ¢å‡½æ•°ä»¥æ”¯æŒ FP16 ç²¾åº¦
def convert_to_openvino(onnx_path, precision="FP16"):
    """å°† ONNX æ¨¡å‹è½¬æ¢ä¸º OpenVINO IR æ ¼å¼ (æ”¯æŒ FP16)"""
    try:
        from openvino.tools import mo
        from openvino.runtime import serialize

        # è®¾ç½®è¾“å‡ºè·¯å¾„å’Œæ–‡ä»¶å
        model_name = os.path.splitext(os.path.basename(onnx_path))[0]
        output_dir = "../FP16/ov_model"
        output_path = os.path.join(output_dir, f"{model_name}_{precision.lower()}")

        print(f"ğŸ”„ æ­£åœ¨è½¬æ¢æ¨¡å‹ä¸º OpenVINO IR ({precision})...")
        print(f"è¾“å…¥æ¨¡å‹: {onnx_path}")
        print(f"è¾“å‡ºè·¯å¾„: {output_path}")

        # è½¬æ¢æ¨¡å‹
        ov_model = mo.convert_model(
            input_model=onnx_path,
            compress_to_fp16=(precision == "FP16")  # å…³é”®ä¿®æ”¹ï¼šå¯ç”¨ FP16 å‹ç¼©
        )

        # ä¿å­˜æ¨¡å‹
        serialize(ov_model, output_path + ".xml", output_path + ".bin")
        print(f"âœ… æ¨¡å‹è½¬æ¢å®Œæˆ: {output_path}.xml")
        return output_path + ".xml"

    except Exception as e:
        print(f"âŒ OpenVINO æ¨¡å‹è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def convert_step_by_step(onnx_path, xml_path):
    """åˆ†æ­¥è½¬æ¢ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
    try:
        print("å°è¯•åˆ†æ­¥è½¬æ¢...")
        # 1. è¯»å– ONNX æ¨¡å‹
        core = ov.Core()
        model = core.read_model(onnx_path)

        # 2. è®¾ç½®åŠ¨æ€è¾“å…¥å½¢çŠ¶
        input_layer = model.input(0)
        partial_shape = input_layer.get_partial_shape()
        if partial_shape[2].is_dynamic and partial_shape[3].is_dynamic:
            print("âœ… æ¨¡å‹å·²æ”¯æŒåŠ¨æ€è¾“å…¥")
        else:
            print("âš ï¸ è®¾ç½®åŠ¨æ€è¾“å…¥å½¢çŠ¶")
            partial_shape[2] = -1
            partial_shape[3] = -1
            model.reshape({input_layer: partial_shape})

        # 3. ä¿å­˜ä¸º FP16 æ ¼å¼
        ov.save_model(model, xml_path, compress_to_fp16=True)

        if os.path.exists(xml_path):
            print(f"âœ… åˆ†æ­¥è½¬æ¢æˆåŠŸ: {xml_path}")
            return xml_path
        else:
            print("âŒ åˆ†æ­¥è½¬æ¢åæ–‡ä»¶æœªç”Ÿæˆ")
            return None

    except Exception as e:
        print(f"âŒ åˆ†æ­¥è½¬æ¢å¤±è´¥: {e}")
        return None


# ========== GPU æ¨ç† (FP16 ç‰ˆæœ¬) ==========
def run_gpu_inference(compiled_model, input_layer_name, input_image_path, output_image_path):
    """åœ¨å·²ç¼–è¯‘çš„æ¨¡å‹ä¸Šè¿è¡Œæ¨ç†"""
    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        total_start = time.time()

        # å‡†å¤‡è¾“å…¥å›¾åƒ
        image_load_start = time.time()
        img = cv2.imread(input_image_path)
        if img is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {input_image_path}")
            # åˆ›å»ºé»˜è®¤å›¾åƒ
            img = np.zeros((256, 256, 3), dtype=np.uint8)
            cv2.putText(img, "GPU Test", (50, 128),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            print("âœ… åˆ›å»ºé»˜è®¤æµ‹è¯•å›¾åƒ")
        image_load_time = time.time() - image_load_start

        # è°ƒæ•´å°ºå¯¸ä¸º 64 çš„å€æ•°
        resize_start = time.time()
        h, w = img.shape[:2]

        # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸æ˜¯å¦å¤§äº1920x1080
        max_width = 1920
        max_height = 1080
        scale_down = False

        if w > max_width or h > max_height:
            print(f"âš ï¸ å›¾ç‰‡å°ºå¯¸ {w}x{h} å¤§äº {max_width}x{max_height}ï¼Œå°†è¿›è¡Œç¼©æ”¾")
            scale_down = True

            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            scale_ratio = min(max_width / w, max_height / h)
            new_w = int(w * scale_ratio)
            new_h = int(h * scale_ratio)

            # ç¡®ä¿ç¼©æ”¾åçš„å°ºå¯¸æ˜¯64çš„å€æ•°
            new_w = (new_w // 64) * 64
            new_h = (new_h // 64) * 64

            print(f"ğŸ” ç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.4f}, æ–°å°ºå¯¸: {new_w}x{new_h}")

            # æ‰§è¡Œç¼©æ”¾
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        else:

            new_h = (h // 64) * 64
            new_w = (w // 64) * 64


            if new_h != h or new_w != w:
                print(f"è°ƒæ•´å›¾åƒå°ºå¯¸: {w}x{h} -> {new_w}x{new_h}")
                img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)

        resize_time = time.time() - resize_start

        # é¢„å¤„ç†
        preprocess_start = time.time()
        input_data = img.astype(np.float16) / 255.0
        input_data = np.transpose(input_data, (2, 0, 1))
        input_data = np.expand_dims(input_data, axis=0)
        preprocess_time = time.time() - preprocess_start

        # åˆ›å»ºæ¨ç†è¯·æ±‚
        infer_request = compiled_model.create_infer_request()

        # æ¨ç†
        inference_start = time.time()
        infer_request.infer({input_layer_name: input_data})
        inference_time = time.time() - inference_start
        print(f"â±ï¸ æ¨ç†æ—¶é—´: {inference_time:.4f} ç§’")

        # è·å–ç»“æœ
        get_results_start = time.time()
        output_layer = compiled_model.output(0)
        result = infer_request.get_output_tensor(output_layer.index).data
        get_results_time = time.time() - get_results_start

        # åå¤„ç†
        postprocess_start = time.time()
        output_data = np.squeeze(result, axis=0)
        output_data = np.transpose(output_data, (1, 2, 0))

        # æ£€æŸ¥æ•°æ®ç±»å‹å¹¶è½¬æ¢
        if output_data.dtype != np.uint8:

            output_data = np.clip(output_data * 255, 0, 255).astype(np.uint8)
        postprocess_time = time.time() - postprocess_start

        # ä¿å­˜ç»“æœ
        save_start = time.time()
        cv2.imwrite(output_image_path, output_data)
        save_time = time.time() - save_start

        # è®¡ç®—æ€»æ—¶é—´
        total_time = time.time() - total_start

        # æ‰“å°è¯¦ç»†æ—¶é—´ç»Ÿè®¡
        print(f"âœ… ç»“æœä¿å­˜è‡³: {output_image_path}")
        print("\nâ±ï¸ æ—¶é—´ç»Ÿè®¡ (FP16):")
        print(f"  å›¾åƒåŠ è½½: {image_load_time:.4f} ç§’")
        print(f"  å›¾åƒè°ƒæ•´: {resize_time:.4f} ç§’")
        print(f"  é¢„å¤„ç†: {preprocess_time:.4f} ç§’")
        print(f"  æ¨ç†æ‰§è¡Œ: {inference_time:.4f} ç§’")
        print(f"  ç»“æœè·å–: {get_results_time:.4f} ç§’")
        print(f"  åå¤„ç†: {postprocess_time:.4f} ç§’")
        print(f"  ç»“æœä¿å­˜: {save_time:.4f} ç§’")
        print(f"---------------------------")
        print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.4f} ç§’")
        print(f"  å¹³å‡FPS: {1 / total_time:.2f}" if total_time > 0 else "æ— æ³•è®¡ç®—FPS")

        return True

    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ========== ä¸»å‡½æ•° (FP16 ç‰ˆæœ¬) ==========
def main():
    print("=" * 50)
    print("Intel GPU (ARC) è¶…åˆ†è¾¨ç‡æ¼”ç¤º (FP16 æ¨¡å¼)")
    print("=" * 50)
    # è®°å½•æ€»å¼€å§‹æ—¶é—´
    program_start = time.time()

    # 1. ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨
    if not download_model():
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
        return

    # 2. å¯¼å‡º ONNX æ¨¡å‹
    onnx_path = export_realesrgan_to_onnx()
    if onnx_path is None or not os.path.exists(onnx_path):
        print("âŒ ONNX å¯¼å‡ºå¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
        return

    # 3. è½¬æ¢ä¸º OpenVINO æ ¼å¼
    ov_path = convert_to_openvino(onnx_path, precision="FP16")  # ä¿®æ”¹ä¸º FP16
    if ov_path is None or not os.path.exists(ov_path):
        print("âŒ OpenVINO è½¬æ¢å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
        return

    # 4. åˆå§‹åŒ– OpenVINO å¹¶ç¼–è¯‘æ¨¡å‹
    print("\n" + "=" * 50)
    print("åˆå§‹åŒ– GPU æ¨ç†å¼•æ“...")
    print("=" * 50)

    # åˆå§‹åŒ– OpenVINO æ ¸å¿ƒ
    core = Core()

    # æ£€æŸ¥å¯ç”¨è®¾å¤‡
    devices = core.available_devices
    print(f"å¯ç”¨è®¾å¤‡: {devices}")

    # å¼ºåˆ¶é€‰æ‹© GPU è®¾å¤‡
    device = "GPU"
    if "GPU" in devices:
        print("âœ… ä½¿ç”¨ Intel ARC GPU (æ ¸æ˜¾)")
    else:
        print("âŒ GPU ä¸å¯ç”¨ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œ")
        return

    # è¯»å–æ¨¡å‹
    model_read_start = time.time()
    model = core.read_model(ov_path)
    model_read_time = time.time() - model_read_start
    print(f"â±ï¸ æ¨¡å‹è¯»å–æ—¶é—´: {model_read_time:.4f} ç§’")

    # è®¾ç½®åŠ¨æ€è¾“å…¥å½¢çŠ¶
    input_layer = model.input(0)
    partial_shape = input_layer.get_partial_shape()


    if partial_shape[2].is_static and partial_shape[3].is_static:
        print("ğŸ”„ è®¾ç½®æ¨¡å‹è¾“å…¥ä¸ºåŠ¨æ€å½¢çŠ¶")
        partial_shape[2] = -1  # åŠ¨æ€é«˜åº¦
        partial_shape[3] = -1  # åŠ¨æ€å®½åº¦
        model.reshape({input_layer: partial_shape})
    else:
        print("âœ… æ¨¡å‹å·²æ”¯æŒåŠ¨æ€è¾“å…¥")

    # GPU ä¼˜åŒ–é…ç½® - ä½¿ç”¨ FP16
    config = {
        props.hint.performance_mode(): props.hint.PerformanceMode.THROUGHPUT,
        props.hint.execution_mode(): props.hint.ExecutionMode.PERFORMANCE,
        props.enable_profiling(): False,
        props.hint.inference_precision(): Type.f16
    }
    print("âœ… åº”ç”¨ GPU ä¼˜åŒ–é…ç½® (FP16)")

    # ç¼–è¯‘æ¨¡å‹
    compile_start = time.time()
    compiled_model = core.compile_model(model, device, config)
    compile_time = time.time() - compile_start
    print(f"â±ï¸ æ¨¡å‹ç¼–è¯‘æ—¶é—´: {compile_time:.4f} ç§’")

    # è·å–è¾“å…¥å±‚ä¿¡æ¯
    input_layer = compiled_model.input(0)
    input_layer_name = input_layer.get_any_name()
    print(f"âœ… è¾“å…¥å±‚åç§°: {input_layer_name}")

    # 5. è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    script_dir = os.path.dirname(os.path.abspath(__file__))
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for filename in os.listdir(script_dir):
        if any(filename.lower().endswith(ext) for ext in image_extensions):
            image_files.append(filename)

    if not image_files:
        print("âŒ å½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡:")
    for img in image_files:
        print(f"  - {img}")

    # 6. å¤„ç†æ¯å¼ å›¾ç‰‡
    processed_count = 0
    for input_image in image_files:

        if "-output" in input_image:
            continue


        filename, ext = os.path.splitext(input_image)
        output_image = f"{filename}-output{ext}"
        output_path = os.path.join(script_dir, output_image)
        input_path = os.path.join(script_dir, input_image)

        print(f"\n{'=' * 50}")
        print(f"å¤„ç†å›¾ç‰‡: {input_image}")
        print(f"è¾“å‡ºå°†ä¿å­˜è‡³: {output_image}")
        print("=" * 50)

        # ä½¿ç”¨å·²ç¼–è¯‘çš„æ¨¡å‹è¿è¡Œæ¨ç†
        inference_start = time.time()
        success = run_gpu_inference(compiled_model, input_layer_name, input_path, output_path)
        inference_time = time.time() - inference_start

        if success:
            print(f"âœ… å›¾ç‰‡å¤„ç†å®Œæˆ: {output_image}")
            print(f"â±ï¸ å¤„ç†æ—¶é—´: {inference_time:.4f} ç§’")
            processed_count += 1
        else:
            print(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {input_image}")

    # è®¡ç®—æ€»ç¨‹åºæ—¶é—´
    total_program_time = time.time() - program_start
    print("\n" + "=" * 50)
    if processed_count > 0:
        print(f"ğŸ‰ å¤„ç†å®Œæˆ! å…±å¤„ç† {processed_count}/{len(image_files)} å¼ å›¾ç‰‡ (FP16 æ¨¡å¼)")
        print(f"æ€»ç¨‹åºè¿è¡Œæ—¶é—´: {total_program_time:.4f} ç§’")


        try:
            import matplotlib.pyplot as plt

            # è·å–æœ€åå¤„ç†çš„å›¾ç‰‡è·¯å¾„
            input_image = image_files[-1]  # æœ€åå¤„ç†çš„å›¾ç‰‡
            filename, ext = os.path.splitext(input_image)
            output_image = f"{filename}-output{ext}"

            fig, axs = plt.subplots(1, 2, figsize=(12, 6))

            # åŸå§‹å›¾åƒ
            input_path = os.path.join(script_dir, input_image)
            orig_img = cv2.imread(input_path)
            if orig_img is None:
                print(f"âš ï¸ æ— æ³•è¯»å–åŸå§‹å›¾åƒ: {input_path}")
                orig_img = np.zeros((256, 256, 3), dtype=np.uint8)
                cv2.putText(orig_img, "Missing", (50, 128),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            else:
                orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)

            axs[0].imshow(orig_img)
            axs[0].set_title('åŸå§‹å›¾åƒ')
            axs[0].axis('off')

            # è¶…åˆ†è¾¨ç‡ç»“æœ
            output_path = os.path.join(script_dir, output_image)
            result_img = cv2.imread(output_path)
            if result_img is None:
                print(f"âš ï¸ æ— æ³•è¯»å–ç»“æœå›¾åƒ: {output_path}")
                result_img = np.zeros((256, 256, 3), dtype=np.uint8)
                cv2.putText(result_img, "Missing", (50, 128),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            else:
                result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)

            axs[1].imshow(result_img)
            axs[1].set_title('è¶…åˆ†è¾¨ç‡ç»“æœ (FP16)')
            axs[1].axis('off')


        except ImportError:
            print("âš ï¸ Matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å›¾åƒå¯¹æ¯”")
    else:
        print("âŒ æ‰€æœ‰å›¾ç‰‡å¤„ç†å¤±è´¥")


if __name__ == "__main__":
    # æ·»åŠ  OpenVINO åˆ° PATH
    try:
        import openvino

        ov_path = os.path.dirname(openvino.__file__)
        scripts_path = os.path.join(ov_path, "..", "..", "Scripts")
        if os.path.exists(scripts_path) and scripts_path not in os.environ["PATH"]:
            os.environ["PATH"] += os.pathsep + os.path.abspath(scripts_path)
            print(f"âœ… æ·»åŠ  OpenVINO åˆ° PATH: {scripts_path}")
    except ImportError:
        print("âŒ OpenVINO æœªå®‰è£…")

        try:
            import pip

            pip.main(['install', 'openvino-dev[onnx]==2023.3.0'])
            print("âœ… å·²å®‰è£… OpenVINO")
        except:
            print("âŒ æ— æ³•è‡ªåŠ¨å®‰è£… OpenVINOï¼Œè¯·æ‰‹åŠ¨å®‰è£…")

    main()
